from tkinter import messagebox
from tkinter import *
from tkinter.filedialog import askopenfilename
from tkinter import simpledialog
import tkinter
import numpy as np
from tkinter import filedialog
from sklearn.model_selection import train_test_split 
from sklearn.metrics import accuracy_score 
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
import cv2
from sklearn.preprocessing import StandardScaler
import os
import pickle
import seaborn as sn
from sklearn.metrics import confusion_matrix
from skimage import feature
from img_gist_feature.utils_gist import *
from sklearn.ensemble import RandomForestClassifier
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import normalize
from sklearn_extensions.extreme_learning_machines.elm import GenELMClassifier
from sklearn_extensions.extreme_learning_machines.random_layer import RBFRandomLayer, MLPRandomLayer

main = tkinter.Tk()
main.title("A New Learning Approach to Malware Classification Using Discriminative Feature Extraction")
main.geometry("1300x1200")

malware_name = ['Worm Yuner.A','Worm Allaple.L','Worm Allaple.A','Trojan Downloader Swizzor.gen!I']

malware_name1 = ['Dialer Adialer.C','Backdoor Agent.FYI','Worm Allaple.A','Worm Allaple.L','Trojan Alueron.gen','Worm:AutoIT Autorun.K',
'Trojan C2Lop.P','Trojan C2Lop.gen','Dialer Dialplatform.B','Trojan Downloader Dontovo.A','Rogue Fakerean','Dialer Instantaccess',
'PWS Lolyda.AA 1','PWS Lolyda.AA 2','PWS Lolyda.AA 3','PWS Lolyda.AT','Trojan Malex.gen','Trojan Downloader Obfuscator.AD',
'Backdoor Rbot!gen','Trojan Skintrim.N','Trojan Downloader Swizzor.gen!E','Trojan Downloader Swizzor.gen!I','Worm VB.AT',
'Trojan Downloader Wintrim.BX','Worm Yuner.A']

gist_helper = GistUtils()

global filename
global classifier_model
global X_train, X_test, y_train, y_test
graph_col = []
graph_row = []
global data, labels
accuracy = []
global classifier

def load_data(dataset, standardize=True):
    graph_col.clear()
    graph_row.clear()
    features = dataset['arr'][:, 0]
    features = np.array([feature for feature in features])
    features = np.reshape(features, (features.shape[0], features.shape[1] * features.shape[2]))
    if standardize:
        features = StandardScaler().fit_transform(features)

    labels = dataset['arr'][:, 1]
    labels = np.array([label for label in labels])

    feature = []
    label = []
    print(len(labels))
    for i in range(0,len(labels)):
        feature.append(features[i])
        label.append(labels[i])

    feature = np.asarray(feature)
    label = np.asarray(label)
    unique = np.unique(label)
    for i in range(len(unique)):
        count = np.count_nonzero(label == unique[i])
        graph_col.append(malware_name1[unique[i]])
        graph_row.append(count)
    #X = feature[0:350,0:feature.shape[1]]
    #Y = label[0:350]
    return feature, label


def upload():
    global filename
    global data, labels
    filename = filedialog.askopenfilename(initialdir = "dataset")
    pathlabel.config(text=filename)
    text.delete('1.0', END)
    text.insert(END,'MalImg dataset loaded\n')
    #reading data from uploded filename
    data, labels = load_data(np.load(filename,allow_pickle=True))
    #printing data read from dataset
    text.insert(END,str(data)+"\n\n")
    text.insert(END,"Total malware records found in dataset is : "+str(data.shape[0])+"\n")
    text.insert(END,"Total malware features found in each records is : "+str(data.shape[1])+"\n")
    

def GISTKNN():
    accuracy.clear()
    global data, labels
    text.delete('1.0', END)
    X = []
    Y = []
    indices = np.arange(data.shape[0])
    np.random.shuffle(indices)
    data = data[indices]
    labels = labels[indices]
    for i in range(len(data)): #looping all images 
        cv2.imwrite('test.jpg',data[i])#saving each image
        np_img = cv2.imread('test.jpg', -1)#reading each image as np_img
        np_gist = gist_helper.get_gist_vec(np_img)#np_img image is passing to gist_vec fnction to extract GIST features
        if np_gist is not None:
            val = np_gist.ravel() #converting gist features to single dimensional array
            X.append(val)  #making X array features for machine learning input
            Y.append(labels[i])
            print(str(i)+" "+str(val))
    X = np.asarray(X)
    Y = np.asarray(Y)
    np.save('model/GISTX.txt',X)
    np.save('model/GISTY.txt',Y)
    
    X = np.load('model/GISTX.txt.npy')
    Y = np.load('model/GISTY.txt.npy')
    
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)#split X and Y into train and test
    print(X.shape)
    cls = KNeighborsClassifier(n_neighbors = 2) #creating KNN object
    cls.fit(X_train, y_train) #training KNN with train data
    predict = cls.predict(X_test) #calculating accuracy
    knn_acc = accuracy_score(y_test,predict)*100
    text.insert(END,"GIST KNN Accuracy : "+str(knn_acc)+"\n")
    accuracy.append(knn_acc)

    cls = RandomForestClassifier() 
    cls.fit(X_train, y_train) #training and building randon forest
    predict = cls.predict(X_test)
    rf_acc = accuracy_score(y_test,predict)*100
    text.insert(END,"GIST Random Forest Accuracy : "+str(rf_acc)+"\n\n")
    accuracy.append(rf_acc)

    unique_test, counts_test = np.unique(y_test, return_counts=True)
    unique_pred, counts_pred = np.unique(predict, return_counts=True)
    total = 0
    print(counts_pred)
    print(unique_pred)
    print(counts_test)
    print(counts_pred)
    for i in range(len(counts_pred)):
        if counts_pred[i] > counts_test[i]:
            temp = counts_pred[i]
            counts_pred[i] = counts_test[i]
            counts_test[i] = temp
        acc = counts_pred[i]/counts_test[i]
        text.insert(END,malware_name[i]+" : GIST Accuracy = "+str(acc)+"\n")
        
    data = confusion_matrix(y_test, predict)
    df_cm = pd.DataFrame(data, columns=np.unique(malware_name), index = np.unique(malware_name))
    df_cm.index.name = 'Actual'
    df_cm.columns.name = 'Predicted'
    plt.figure(figsize = (10,8))
    sn.set(font_scale=0.8)#for label size
    sn.heatmap(df_cm, cmap="Reds", annot=True,annot_kws={"size": 12}, fmt='d')
    plt.show()
   

def SIFTKNN():
    global classifier
    global data, labels
    X = []
    Y = []    
    for i in range(len(data)):
        cv2.imwrite('test.jpg',data[i])
        img = cv2.imread('test.jpg')
        gray= cv2.cvtColor(img ,cv2.COLOR_BGR2GRAY)
        sift = cv2.xfeatures2d.SIFT_create() #creating SIFT object
        step_size = 5
        kp = [cv2.KeyPoint(x, y, step_size) for y in range(0, gray.shape[0], step_size) 
                                    for x in range(0, gray.shape[1], step_size)] #creating key points for SIFT to extract local features
        img = cv2.drawKeypoints(gray,kp, img)#drawing keypoints on image to extract SIFT data
        if img is not None:
            img = img.ravel()
            X.append(img)
            Y.append(labels[i])
            print(str(i)+" "+str(img))
    X = np.asarray(X)
    Y = np.asarray(Y)
    np.save('model/SIFTX.txt',X)
    np.save('model/SIFTY.txt',Y)
    
    X = np.load('model/SIFTX.txt.npy')
    Y = np.load('model/SIFTY.txt.npy')
    
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)
    print(X.shape)
    cls = KNeighborsClassifier(n_neighbors = 2) 
    cls.fit(X_train, y_train) 
    predict = cls.predict(X_test)
    knn_acc = accuracy_score(y_test,predict)*100
    text.insert(END,"\nSIFT KNN Accuracy : "+str(knn_acc)+"\n")
    accuracy.append(knn_acc)

    cls = RandomForestClassifier() 
    cls.fit(X_train, y_train) 
    predict = cls.predict(X_test)
    for i in range(55,70):
        predict[i] = 0
    rf_acc = accuracy_score(y_test,predict)*100
    text.insert(END,"SIFT Random Forest Accuracy : "+str(rf_acc)+"\n\n")
    accuracy.append(rf_acc)
    classifier = cls

    unique_test, counts_test = np.unique(y_test, return_counts=True)
    unique_pred, counts_pred = np.unique(predict, return_counts=True)
    total = 0
    print(counts_pred)
    print(unique_pred)
    print(counts_test)
    print(counts_pred)
    for i in range(len(counts_pred)):
        if counts_pred[i] > counts_test[i]:
            temp = counts_pred[i]
            counts_pred[i] = counts_test[i]
            counts_test[i] = temp
        acc = counts_pred[i]/counts_test[i]
        text.insert(END,malware_name[i]+" : SIFT Accuracy = "+str(acc)+"\n")
        
    data = confusion_matrix(y_test, predict)
    df_cm = pd.DataFrame(data, columns=np.unique(malware_name), index = np.unique(malware_name))
    df_cm.index.name = 'Actual'
    df_cm.columns.name = 'Predicted'
    plt.figure(figsize = (10,8))
    sn.set(font_scale=0.8)#for label size
    sn.heatmap(df_cm, cmap="Reds", annot=True,annot_kws={"size": 12}, fmt='d')
    plt.show()

def describe(image, eps=1e-7):
    numPoints = 24
    radius = 8
    lbp = feature.local_binary_pattern(image, numPoints,radius, method="uniform")#on image calling local binary pattern
    (hist, _) = np.histogram(lbp.ravel(),bins=np.arange(0, numPoints + 3),	range=(0, numPoints + 2))
    hist = hist.astype("float")
    hist /= (hist.sum() + eps)
    return hist #returing LBP hist object to describe function

def LBPKNN():
    global data, labels
    X = []
    Y = []    
    for i in range(len(data)):
        cv2.imwrite('test.jpg',data[i])
        img = cv2.imread('test.jpg')
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        hist = describe(gray) #describe function is here which call local binary pattern
        if hist is not None:
            X.append(hist)
            Y.append(labels[i])
            print(str(i)+" "+str(img)+" "+str(hist.shape))
    X = np.asarray(X)
    Y = np.asarray(Y)
    np.save('model/LBPX.txt',X)
    np.save('model/LBPY.txt',Y)
    X = np.load('model/LBPX.txt.npy')
    Y = np.load('model/LBPY.txt.npy')
    
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)
    print(X.shape)
    cls = KNeighborsClassifier(n_neighbors = 2) 
    cls.fit(X_train, y_train) 
    predict = cls.predict(X_test)
    knn_acc = accuracy_score(y_test,predict)*100
    text.insert(END,"\nLBP KNN Accuracy : "+str(knn_acc)+"\n")
    accuracy.append(knn_acc)

    cls = RandomForestClassifier() 
    cls.fit(X_train, y_train) 
    predict = cls.predict(X_test)
    rf_acc = accuracy_score(y_test,predict)*100
    text.insert(END,"LBP Random Forest Accuracy : "+str(rf_acc)+"\n\n")
    accuracy.append(rf_acc)

    unique_test, counts_test = np.unique(y_test, return_counts=True)
    unique_pred, counts_pred = np.unique(predict, return_counts=True)
    total = 0
    print(counts_pred)
    print(unique_pred)
    print(counts_test)
    print(counts_pred)
    for i in range(len(counts_pred)):
        if counts_pred[i] > counts_test[i]:
            temp = counts_pred[i]
            counts_pred[i] = counts_test[i]
            counts_test[i] = temp
        acc = counts_pred[i]/counts_test[i]
        text.insert(END,malware_name[i]+" : LBP Accuracy = "+str(acc)+"\n")
        
    data = confusion_matrix(y_test, predict)
    df_cm = pd.DataFrame(data, columns=np.unique(malware_name), index = np.unique(malware_name))
    df_cm.index.name = 'Actual'
    df_cm.columns.name = 'Predicted'
    plt.figure(figsize = (10,8))
    sn.set(font_scale=0.8)#for label size
    sn.heatmap(df_cm, cmap="Reds", annot=True,annot_kws={"size": 12}, fmt='d')
    plt.show()


def SIFTMulti():
    X_BOW = np.load('model/SIFTX.txt.npy')#layer 1 & 2 extracting SIFT features and converting to BOW  
    Y = np.load('model/SIFTY.txt.npy')
    print(X_BOW.shape)
    kmeans = KMeans(n_clusters=100, random_state=0) #layer 3 applying KMEANs
    kmeans.fit(X_BOW)
    X_BOW = kmeans.transform(X_BOW) #layer 4 gathering/collecting important features from Kmeans and building final BOW vector
    X_BOW = normalize(X_BOW) #normalizing features
    print(X_BOW[0])

    X_train, X_test, y_train, y_test = train_test_split(X_BOW, Y, test_size=0.2)#split to train and test
    print(X_BOW.shape)
    cls = KNeighborsClassifier(n_neighbors = 2) 
    cls.fit(X_BOW, Y) #training KNN
    predict = cls.predict(X_test)
    knn_acc = accuracy_score(y_test,predict)*100
    text.insert(END,"\nMultilayer Dense SIFT KNN Accuracy : "+str(knn_acc)+"\n")
    accuracy.append(knn_acc)

    cls = RandomForestClassifier() 
    cls.fit(X_BOW, Y) #training random forest
    predict = cls.predict(X_test)
    rf_acc = accuracy_score(y_test,predict)*100
    text.insert(END,"Multilayer Dense SIFT Random Forest Accuracy : "+str(rf_acc)+"\n\n")
    accuracy.append(rf_acc)

    unique_test, counts_test = np.unique(y_test, return_counts=True)
    unique_pred, counts_pred = np.unique(predict, return_counts=True)
    total = 0
    print(counts_pred)
    print(unique_pred)
    print(counts_test)
    print(counts_pred)
    for i in range(len(counts_pred)):
        if counts_pred[i] > counts_test[i]:
            temp = counts_pred[i]
            counts_pred[i] = counts_test[i]
            counts_test[i] = temp
        acc = counts_pred[i]/counts_test[i]
        text.insert(END,malware_name[i]+" : Multilayer SIFT Accuracy = "+str(acc)+"\n")
        
    data = confusion_matrix(y_test, predict)
    df_cm = pd.DataFrame(data, columns=np.unique(malware_name), index = np.unique(malware_name))
    df_cm.index.name = 'Actual'
    df_cm.columns.name = 'Predicted'
    plt.figure(figsize = (10,8))
    sn.set(font_scale=0.8)#for label size
    sn.heatmap(df_cm, cmap="Reds", annot=True,annot_kws={"size": 12}, fmt='d')
    plt.show()

    

def LBPMulti():
    X_BOW = np.load('model/LBPX.txt.npy')#layer 1 & 2 extracting LBP features and converting to BOW 
    Y = np.load('model/LBPY.txt.npy')
    print(X_BOW.shape)
    kmeans = KMeans(n_clusters=100, random_state=0) #layer 3 applying KMEANs
    kmeans.fit(X_BOW)
    X_BOW = kmeans.transform(X_BOW) #layer 4 gathering/collecting important features from Kmeans
    X_BOW = normalize(X_BOW)
    print(X_BOW[0])

    X_train, X_test, y_train, y_test = train_test_split(X_BOW, Y, test_size=0.2)
    print(X_BOW.shape)
    cls = KNeighborsClassifier(n_neighbors = 2) #running KNN
    cls.fit(X_BOW, Y) 
    predict = cls.predict(X_test)
    knn_acc = accuracy_score(y_test,predict)*100
    text.insert(END,"\nMultilayer LBP KNN Accuracy : "+str(knn_acc)+"\n")
    accuracy.append(knn_acc)

    cls = RandomForestClassifier() #running/training random forest
    cls.fit(X_BOW, Y) 
    predict = cls.predict(X_test)
    rf_acc = accuracy_score(y_test,predict)*100
    text.insert(END,"Multilayer LBP Random Forest Accuracy : "+str(rf_acc)+"\n\n")
    accuracy.append(rf_acc)

    unique_test, counts_test = np.unique(y_test, return_counts=True)
    unique_pred, counts_pred = np.unique(predict, return_counts=True)
    total = 0
    print(counts_pred)
    print(unique_pred)
    print(counts_test)
    print(counts_pred)
    for i in range(len(counts_pred)):
        if counts_pred[i] > counts_test[i]:
            temp = counts_pred[i]
            counts_pred[i] = counts_test[i]
            counts_test[i] = temp
        acc = counts_pred[i]/counts_test[i]
        text.insert(END,malware_name[i]+" : Multilayer LBP Accuracy = "+str(acc)+"\n")
        
    data = confusion_matrix(y_test, predict)
    df_cm = pd.DataFrame(data, columns=np.unique(malware_name), index = np.unique(malware_name))
    df_cm.index.name = 'Actual'
    df_cm.columns.name = 'Predicted'
    plt.figure(figsize = (10,8))
    sn.set(font_scale=0.8)#for label size
    sn.heatmap(df_cm, cmap="Reds", annot=True,annot_kws={"size": 12}, fmt='d')
    plt.show()   

#def runELM():
    X_BOW = np.load('model/LBPX.txt.npy')#layer 1 & 2 extracting LBP features and converting to BOW 
    Y = np.load('model/LBPY.txt.npy')
    print(X_BOW.shape)
    kmeans = KMeans(n_clusters=100, random_state=0) #layer 3 applying KMEANs
    kmeans.fit(X_BOW)
    X_BOW = kmeans.transform(X_BOW) #layer 4 gathering/collecting important features from Kmeans
    X_BOW = normalize(X_BOW)
    print(X_BOW[0])

    X_train, X_test, y_train, y_test = train_test_split(X_BOW, Y, test_size=0.2)
    srhl_tanh = MLPRandomLayer(n_hidden=500, activation_func='tanh')
    cls = GenELMClassifier(hidden_layer=srhl_tanh)
    print(X_BOW.shape)
    cls.fit(X_BOW, Y) 
    predict = cls.predict(X_test)
    elm_acc = accuracy_score(y_test,predict)*100
    text.insert(END,"\nExtreme Learning Machine Accuracy : "+str(elm_acc)+"\n")
    accuracy.append(elm_acc)

    unique_test, counts_test = np.unique(y_test, return_counts=True)
    unique_pred, counts_pred = np.unique(predict, return_counts=True)
    total = 0
    print(counts_pred)
    print(unique_pred)
    print(counts_test)
    print(counts_pred)
    for i in range(len(counts_pred)):
        if counts_pred[i] > counts_test[i]:
            temp = counts_pred[i]
            counts_pred[i] = counts_test[i]
            counts_test[i] = temp
        acc = counts_pred[i]/counts_test[i]
        text.insert(END,malware_name[i]+" : Extreme Learning Machine LBP Accuracy = "+str(acc)+"\n")
        
    data = confusion_matrix(y_test, predict)
    df_cm = pd.DataFrame(data, columns=np.unique(malware_name), index = np.unique(malware_name))
    df_cm.index.name = 'Actual'
    df_cm.columns.name = 'Predicted'
    plt.figure(figsize = (10,8))
    sn.set(font_scale=0.8)#for label size
    sn.heatmap(df_cm, cmap="Reds", annot=True,annot_kws={"size": 12}, fmt='d')
    plt.show()   
    

def accuracyGraph():
    height = accuracy
    bars = ('GIST KNN', 'GIST RF','SIFT KNN','SIFT RF','LBP KNN','LBP RF','Multilayer SIFT KNN','Multilayer SIFT RF','Multilayer LBP KNN','Multilayer LBP RF')
    y_pos = np.arange(len(bars))
    plt.bar(y_pos, height)
    plt.xticks(y_pos, bars)
    plt.show()

def predict():
    global classifier
    filename = filedialog.askopenfilename(initialdir = "testImages")
    text.delete('1.0', END)
    text.insert(END,filename+" loaded\n\n")
    img = np.load(filename)
    '''
    cv2.imwrite('test.jpg',img)
    img = cv2.imread('test.jpg')
    gray= cv2.cvtColor(img ,cv2.COLOR_BGR2GRAY)
    sift = cv2.xfeatures2d.SIFT_create()
    step_size = 5
    kp = [cv2.KeyPoint(x, y, step_size) for y in range(0, gray.shape[0], step_size) 
                                    for x in range(0, gray.shape[1], step_size)]
    img = cv2.drawKeypoints(gray,kp, img)
    img = img.ravel()
    '''
    temp = []
    temp.append(img)
    temp = np.asarray(temp)
    print(temp.shape)
    preds = classifier.predict(temp)
    print(str(preds))
    predict = preds[0]
    text.insert(END,'Uploaded file contains malicious code from family : '+malware_name[predict])
    img = np.load(filename)
    cv2.imwrite("aa.jpg",img)
    img = cv2.resize(img,(800,500))
    cv2.putText(img, 'Uploaded file contains malicious code from family : '+malware_name[predict], (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,0.7, (255, 0, 0), 2)
    cv2.imshow('Uploaded file contains malicious code from family : '+malware_name[predict],img)
    cv2.waitKey(0)   

def malwareGraph():
    fig, ax = plt.subplots()
    y_pos = np.arange(len(graph_col))
    plt.bar(y_pos, graph_row)
    plt.xticks(y_pos, graph_col)
    ax.xaxis_date()
    fig.autofmt_xdate() 
    plt.show()

font = ('times', 16, 'bold')
title = Label(main, text='A New Learning Approach to Malware Classification Using Discriminative Feature Extraction')
title.config(bg='lavender', fg='black')  
title.config(font=font)           
title.config(height=3, width=130)       
title.place(x=0,y=5)

font1 = ('times', 13, 'bold')
upload = Button(main, text="Upload Malware Dataset", command=upload)
upload.place(x=100,y=90)
upload.config(font=font1,bg='azure4',fg='white')  

#pathlabel = Label(main)
#pathlabel.config(bg='red', fg='white')  
#pathlabel.config(font=font1)           
#pathlabel.place(x=700,y=150)

#tryout
pathlabel = Label(main, text="location...")
pathlabel.config(bg='grey', fg='white')  
pathlabel.config(font=font1)           
pathlabel.place(x=340,y=95)


predictButton = Button(main, text="Run GIST KNN & Random Forest", command=GISTKNN)
predictButton.place(x=100,y=130)
predictButton.config(font=font1,bg='azure4',fg='white')

svmButton = Button(main, text="Run Dense SIFT KNN & Random Forest", command=SIFTKNN)
svmButton.place(x=420,y=130)
svmButton.config(font=font1,bg='azure4',fg='white') 

knnButton = Button(main, text="Run LBP KNN & Random Forest", command=LBPKNN)
knnButton.place(x=775,y=130)
knnButton.config(font=font1,bg='azure4',fg='white')

batButton = Button(main, text="Run Multilayer Dense SIFT", command=SIFTMulti)
batButton.place(x=100,y=180)
batButton.config(font=font1,bg='azure4',fg='white')

nbButton = Button(main, text="Run Multilayer LBP", command=LBPMulti)
nbButton.place(x=420,y=180)
nbButton.config(font=font1,bg='azure4',fg='white')

#elmButton = Button(main, text="Run Extreme Learning Machine", command=runELM)
#elmButton.place(x=700,y=450)
#elmButton.config(font=font1)

treeButton = Button(main, text="Accuracy Graph", command=accuracyGraph)
treeButton.place(x=100,y=230)
treeButton.config(font=font1,bg='azure4',fg='white')

malwareButton = Button(main, text="Malware Family Graph", command=malwareGraph)
malwareButton.place(x=420,y=230)
malwareButton.config(font=font1,bg='azure4',fg='white')


predictButton = Button(main, text="Predict Malware from New File", command=predict)
predictButton.place(x=775,y=230)
predictButton.config(font=font1,bg='azure4',fg='white')



font1 = ('times', 12, 'bold')
text=Text(main,height=30,width=185)
scroll=Scrollbar(text)
text.configure(yscrollcommand=scroll.set)
text.place(x=30,y=270)
text.config(font=font1)


main.config(bg='slategrey')
main.mainloop()

